{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import noisereduce as nr\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPreprocessor:\n",
    "    def __init__(self, sample_rate=44100):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def load_audio(self, file_path):\n",
    "        \"\"\"Carga un archivo de audio.\"\"\"\n",
    "        audio, sr = librosa.load(file_path, sr=self.sample_rate)\n",
    "        return audio\n",
    "    \n",
    "    def normalize_volume(self, audio, target_dBFS=-20):\n",
    "        \"\"\"Normaliza el volumen del audio a un nivel objetivo en dBFS.\"\"\"\n",
    "        rms = librosa.feature.rms(y=audio)[0]\n",
    "        mean_rms = np.mean(rms)\n",
    "        current_dBFS = 20 * np.log10(mean_rms) if mean_rms > 0 else -np.inf\n",
    "        adjustment = target_dBFS - current_dBFS\n",
    "        normalized_audio = audio * (10 ** (adjustment / 20))\n",
    "        # Prevenir clipping\n",
    "        normalized_audio = np.clip(normalized_audio, -1.0, 1.0)\n",
    "        return normalized_audio\n",
    "    \n",
    "    def remove_silence(self, audio, top_db=30):\n",
    "        \"\"\"Elimina silencios al inicio y final del audio.\"\"\"\n",
    "        return librosa.effects.trim(audio, top_db=top_db)[0]\n",
    "    \n",
    "    def apply_bandpass_filter(self, audio, lowcut=80, highcut=8000):\n",
    "        \"\"\"Aplica un filtro paso banda para reducir ruido.\"\"\"\n",
    "        nyquist = self.sample_rate // 2\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = signal.butter(4, [low, high], btype='band')\n",
    "        return signal.filtfilt(b, a, audio)\n",
    "    \n",
    "    def reduce_noise(self, audio, noise_audio=None):\n",
    "        \"\"\"Reduce el ruido de un audio utilizando un perfil de ruido.\"\"\"\n",
    "        if noise_audio is None:\n",
    "            noise_audio = audio[:int(len(audio) * 0.1)]\n",
    "        \n",
    "        reduced_audio = nr.reduce_noise(y=audio, y_noise=noise_audio, sr=self.sample_rate)\n",
    "        return reduced_audio\n",
    "    \n",
    "    def clip_prevention(self, audio, threshold=0.95):\n",
    "        \"\"\"Previene el clipping manteniendo la señal dentro de los límites.\"\"\"\n",
    "        max_val = np.max(np.abs(audio))\n",
    "        if max_val > threshold:\n",
    "            audio = audio * (threshold / max_val)\n",
    "        return audio\n",
    "    \n",
    "    def process_audio(self, file_path):\n",
    "        \"\"\"Aplica toda la cadena de preprocesamiento a un archivo de audio.\"\"\"\n",
    "        # Cargar audio\n",
    "        audio = self.load_audio(file_path)\n",
    "        \n",
    "        # Aplicar preprocesamiento\n",
    "        audio = self.remove_silence(audio)\n",
    "        audio = self.normalize_volume(audio)\n",
    "        audio = self.apply_bandpass_filter(audio)\n",
    "        audio = self.reduce_noise(audio)\n",
    "        audio = self.clip_prevention(audio)\n",
    "            \n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VoiceFeatureExtractor:\n",
    "    def __init__(self, sample_rate=44100, n_mfcc=13, n_mels=128, frame_length=0.025, \n",
    "                 frame_step=0.01, nfilt=26, window='hamming'):\n",
    "        \"\"\"\n",
    "        Inicializa el extractor de características.\n",
    "        \n",
    "        Args:\n",
    "            sample_rate (int): Frecuencia de muestreo\n",
    "            n_mfcc (int): Número de coeficientes MFCC\n",
    "            n_mels (int): Número de bandas mel\n",
    "            frame_length (float): Longitud de la ventana en segundos\n",
    "            frame_step (float): Paso entre ventanas en segundos\n",
    "            nfilt (int): Número de filtros mel\n",
    "            window (str): Tipo de ventana ('hamming', 'hanning', etc.)\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_mels = n_mels\n",
    "        self.frame_length = int(frame_length * sample_rate)\n",
    "        self.frame_step = int(frame_step * sample_rate)\n",
    "        self.nfilt = nfilt\n",
    "        self.window = window\n",
    "        \n",
    "    def extract_features(self, audio):\n",
    "        \"\"\"\n",
    "        Extrae todas las características del audio.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Características temporales\n",
    "        features.update(self._extract_temporal_features(audio))\n",
    "        \n",
    "        # 2. Características espectrales\n",
    "        features.update(self._extract_spectral_features(audio))\n",
    "        \n",
    "        # 3. Características cepstrales\n",
    "        features.update(self._extract_cepstral_features(audio))\n",
    "        \n",
    "        # 4. Características de energía\n",
    "        features.update(self._extract_energy_features(audio))\n",
    "        \n",
    "        # 5. Características rítmicas\n",
    "        features.update(self._extract_rhythm_features(audio))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_temporal_features(self, audio):\n",
    "        \"\"\"Extrae características del dominio temporal.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Zero Crossing Rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio, \n",
    "                                               frame_length=self.frame_length, \n",
    "                                               hop_length=self.frame_step)[0]\n",
    "        features.update({\n",
    "            'zcr_mean': np.mean(zcr),\n",
    "            'zcr_std': np.std(zcr),\n",
    "            'zcr_skew': skew(zcr),\n",
    "            'zcr_kurtosis': kurtosis(zcr),\n",
    "            'zcr_median': np.median(zcr)\n",
    "        })\n",
    "        \n",
    "        # Amplitud envelope\n",
    "        envelope = np.abs(scipy.signal.hilbert(audio))\n",
    "        features.update({\n",
    "            'envelope_mean': np.mean(envelope),\n",
    "            'envelope_std': np.std(envelope),\n",
    "            'envelope_skew': skew(envelope),\n",
    "            'envelope_kurtosis': kurtosis(envelope)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_spectral_features(self, audio):\n",
    "        \"\"\"Extrae características del dominio espectral.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Centroide espectral\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, \n",
    "                                                             sr=self.sample_rate,\n",
    "                                                             n_fft=self.frame_length,\n",
    "                                                             hop_length=self.frame_step,\n",
    "                                                             window=self.window)[0]\n",
    "        features.update({\n",
    "            'spectral_centroid_mean': np.mean(spectral_centroids),\n",
    "            'spectral_centroid_std': np.std(spectral_centroids),\n",
    "            'spectral_centroid_skew': skew(spectral_centroids)\n",
    "        })\n",
    "        \n",
    "        # Rolloff espectral\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, \n",
    "                                                          sr=self.sample_rate,\n",
    "                                                          n_fft=self.frame_length,\n",
    "                                                          hop_length=self.frame_step,\n",
    "                                                          window=self.window)[0]\n",
    "        features.update({\n",
    "            'spectral_rolloff_mean': np.mean(spectral_rolloff),\n",
    "            'spectral_rolloff_std': np.std(spectral_rolloff)\n",
    "        })\n",
    "        \n",
    "        # Ancho de banda espectral\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, \n",
    "                                                              sr=self.sample_rate,\n",
    "                                                              n_fft=self.frame_length,\n",
    "                                                              hop_length=self.frame_step,\n",
    "                                                              window=self.window)[0]\n",
    "        features.update({\n",
    "            'spectral_bandwidth_mean': np.mean(spectral_bandwidth),\n",
    "            'spectral_bandwidth_std': np.std(spectral_bandwidth)\n",
    "        })\n",
    "        \n",
    "        # Contraste espectral\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=audio, \n",
    "                                                            sr=self.sample_rate,\n",
    "                                                            n_fft=self.frame_length,\n",
    "                                                            hop_length=self.frame_step)\n",
    "        features.update({\n",
    "            'spectral_contrast_mean': np.mean(spectral_contrast),\n",
    "            'spectral_contrast_std': np.std(spectral_contrast)\n",
    "        })\n",
    "        \n",
    "        # Flatness espectral\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(y=audio,\n",
    "                                                            n_fft=self.frame_length,\n",
    "                                                            hop_length=self.frame_step)[0]\n",
    "        features.update({\n",
    "            'spectral_flatness_mean': np.mean(spectral_flatness),\n",
    "            'spectral_flatness_std': np.std(spectral_flatness)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_cepstral_features(self, audio):\n",
    "        \"\"\"Extrae características cepstrales.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # MFCC y sus derivadas\n",
    "        mfccs = librosa.feature.mfcc(y=audio, \n",
    "                               sr=self.sample_rate, \n",
    "                               n_mfcc=self.n_mfcc,\n",
    "                               n_fft=self.frame_length,\n",
    "                               hop_length=self.frame_step,\n",
    "                               window=self.window,\n",
    "                               n_mels=self.nfilt) \n",
    "    \n",
    "        # Delta y Delta-Delta\n",
    "        mfccs_delta = librosa.feature.delta(mfccs)\n",
    "        mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        \n",
    "        # Estadísticas para cada coeficiente MFCC\n",
    "        for i in range(self.n_mfcc):\n",
    "            features.update({\n",
    "                f'mfcc_{i}_mean': np.mean(mfccs[i]),\n",
    "                f'mfcc_{i}_std': np.std(mfccs[i]),\n",
    "                f'mfcc_{i}_skew': skew(mfccs[i]),\n",
    "                f'mfcc_{i}_delta_mean': np.mean(mfccs_delta[i]),\n",
    "                f'mfcc_{i}_delta_std': np.std(mfccs_delta[i]),\n",
    "                f'mfcc_{i}_delta2_mean': np.mean(mfccs_delta2[i]),\n",
    "                f'mfcc_{i}_delta2_std': np.std(mfccs_delta2[i])\n",
    "            })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_energy_features(self, audio):\n",
    "        \"\"\"Extrae características relacionadas con la energía.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # RMS Energy\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                                frame_length=self.frame_length,\n",
    "                                hop_length=self.frame_step)[0]\n",
    "        features.update({\n",
    "            'rms_mean': np.mean(rms),\n",
    "            'rms_std': np.std(rms),\n",
    "            'rms_skew': skew(rms),\n",
    "            'rms_kurtosis': kurtosis(rms)\n",
    "        })\n",
    "        \n",
    "        # Energía por bandas de frecuencia\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, \n",
    "                                                sr=self.sample_rate,\n",
    "                                                n_fft=self.frame_length,\n",
    "                                                hop_length=self.frame_step,\n",
    "                                                n_mels=self.n_mels,\n",
    "                                                window=self.window)\n",
    "        \n",
    "        # Dividir en tercios el espectrograma mel para energía por bandas\n",
    "        band_size = self.n_mels // 3\n",
    "        for i in range(3):\n",
    "            band = mel_spec[i*band_size:(i+1)*band_size]\n",
    "            features.update({\n",
    "                f'band_{i}_energy_mean': np.mean(np.sum(band, axis=0)),\n",
    "                f'band_{i}_energy_std': np.std(np.sum(band, axis=0))\n",
    "            })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_rhythm_features(self, audio):\n",
    "        \"\"\"Extrae características rítmicas.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Onset strength\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, \n",
    "                                               sr=self.sample_rate,\n",
    "                                               hop_length=self.frame_step)\n",
    "        features.update({\n",
    "            'onset_strength_mean': np.mean(onset_env),\n",
    "            'onset_strength_std': np.std(onset_env)\n",
    "        })\n",
    "        \n",
    "        # Tempo y beats\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, \n",
    "                                         sr=self.sample_rate,\n",
    "                                         hop_length=self.frame_step)\n",
    "        features['tempo'] = tempo\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def process_audio(self, audio):\n",
    "        \"\"\"\n",
    "        Procesa un audio y extrae todas sus características.\n",
    "        \n",
    "        Args:\n",
    "            audio (numpy.array): Señal de audio preprocesada\n",
    "            \n",
    "        Returns:\n",
    "            dict: Diccionario con todas las características\n",
    "        \"\"\"\n",
    "        if len(audio) > self.sample_rate:\n",
    "            audio = audio[:self.sample_rate]\n",
    "        elif len(audio) < self.sample_rate:\n",
    "            audio = np.pad(audio, (0, self.sample_rate - len(audio)))\n",
    "        \n",
    "        return self.extract_features(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(audio_files, preprocessor, feature_extractor):\n",
    "    all_features = []\n",
    "    for idx, file_info in enumerate(audio_files):\n",
    "        # Preprocesar audio\n",
    "        audio = preprocessor.process_audio(file_info['ruta_archivo'])\n",
    "        \n",
    "        # Extraer características\n",
    "        features = feature_extractor.process_audio(audio)\n",
    "        \n",
    "        # Agregar etiquetas\n",
    "        features['palabra'] = file_info['palabra']\n",
    "        # features['persona'] = file_info['persona']\n",
    "        \n",
    "        all_features.append(features)\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Procesados {idx + 1} archivos de {len(audio_files)}\")\n",
    "            \n",
    "    return pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesados 100 archivos de 4000\n",
      "Procesados 200 archivos de 4000\n",
      "Procesados 300 archivos de 4000\n",
      "Procesados 400 archivos de 4000\n",
      "Procesados 500 archivos de 4000\n",
      "Procesados 600 archivos de 4000\n",
      "Procesados 700 archivos de 4000\n",
      "Procesados 800 archivos de 4000\n",
      "Procesados 900 archivos de 4000\n",
      "Procesados 1000 archivos de 4000\n",
      "Procesados 1100 archivos de 4000\n",
      "Procesados 1200 archivos de 4000\n",
      "Procesados 1300 archivos de 4000\n",
      "Procesados 1400 archivos de 4000\n",
      "Procesados 1500 archivos de 4000\n",
      "Procesados 1600 archivos de 4000\n",
      "Procesados 1700 archivos de 4000\n",
      "Procesados 1800 archivos de 4000\n",
      "Procesados 1900 archivos de 4000\n",
      "Procesados 2000 archivos de 4000\n",
      "Procesados 2100 archivos de 4000\n",
      "Procesados 2200 archivos de 4000\n",
      "Procesados 2300 archivos de 4000\n",
      "Procesados 2400 archivos de 4000\n",
      "Procesados 2500 archivos de 4000\n",
      "Procesados 2600 archivos de 4000\n",
      "Procesados 2700 archivos de 4000\n",
      "Procesados 2800 archivos de 4000\n",
      "Procesados 2900 archivos de 4000\n",
      "Procesados 3000 archivos de 4000\n",
      "Procesados 3100 archivos de 4000\n",
      "Procesados 3200 archivos de 4000\n",
      "Procesados 3300 archivos de 4000\n",
      "Procesados 3400 archivos de 4000\n",
      "Procesados 3500 archivos de 4000\n",
      "Procesados 3600 archivos de 4000\n",
      "Procesados 3700 archivos de 4000\n",
      "Procesados 3800 archivos de 4000\n",
      "Procesados 3900 archivos de 4000\n",
      "Procesados 4000 archivos de 4000\n"
     ]
    }
   ],
   "source": [
    "# Crear instancias\n",
    "preprocessor = AudioPreprocessor()\n",
    "feature_extractor = VoiceFeatureExtractor()\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "features_df = create_feature_dataset(df.to_dict('records'), preprocessor, feature_extractor)\n",
    "\n",
    "features_df.to_csv('voice_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
