{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import skew, kurtosis\n",
    "import preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakerFeatureExtractor:\n",
    "    def __init__(self, sample_rate=44100, n_mfcc=13, n_mels=128, frame_length=0.025,\n",
    "                 frame_step=0.01, nfilt=26, window='hamming'):\n",
    "        \"\"\"\n",
    "        Inicializa el extractor de características para identificación de locutor.\n",
    "        \n",
    "        Args:\n",
    "            sample_rate (int): Frecuencia de muestreo\n",
    "            n_mfcc (int): Número de coeficientes MFCC (mayor que para palabras)\n",
    "            n_mels (int): Número de bandas mel\n",
    "            frame_length (float): Longitud de la ventana en segundos\n",
    "            frame_step (float): Paso entre ventanas en segundos\n",
    "            nfilt (int): Número de filtros mel\n",
    "            window (str): Tipo de ventana\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_mels = n_mels\n",
    "        self.frame_length = int(frame_length * sample_rate)\n",
    "        self.frame_step = int(frame_step * sample_rate)\n",
    "        self.nfilt = nfilt\n",
    "        self.window = window\n",
    "    \n",
    "    def extract_features(self, audio):\n",
    "        \"\"\"\n",
    "        Extrae todas las características relevantes para identificación de locutor.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Características fundamentales de la voz\n",
    "        features.update(self._extract_fundamental_features(audio))\n",
    "        \n",
    "        # 2. Características prosódicas\n",
    "        features.update(self._extract_prosodic_features(audio))\n",
    "        \n",
    "        # 3. Características espectrales y cepstrales\n",
    "        features.update(self._extract_spectral_features(audio))\n",
    "        \n",
    "        # 4. Características de calidad de voz\n",
    "        features.update(self._extract_voice_quality_features(audio))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_fundamental_features(self, audio):\n",
    "        \"\"\"Extrae características fundamentales de la voz.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Pitch (F0) usando PYIN (más preciso que YIN)\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(audio, \n",
    "                                                   fmin=librosa.note_to_hz('C2'),\n",
    "                                                   fmax=librosa.note_to_hz('C7'),\n",
    "                                                   sr=self.sample_rate)\n",
    "        \n",
    "        # Estadísticas de F0 (solo para frames con voz)\n",
    "        f0_voiced = f0[voiced_flag]\n",
    "        if len(f0_voiced) > 0:\n",
    "            features.update({\n",
    "                'f0_mean': np.mean(f0_voiced),\n",
    "                'f0_std': np.std(f0_voiced),\n",
    "                'f0_min': np.min(f0_voiced),\n",
    "                'f0_max': np.max(f0_voiced),\n",
    "                'f0_range': np.ptp(f0_voiced),\n",
    "                'f0_skew': skew(f0_voiced),\n",
    "                'f0_kurtosis': kurtosis(f0_voiced)\n",
    "            })\n",
    "        \n",
    "        # Porcentaje de frames con voz\n",
    "        features['voiced_fraction'] = np.mean(voiced_flag)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_prosodic_features(self, audio):\n",
    "        \"\"\"Extrae características prosódicas.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Energía y sus variaciones\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                                frame_length=self.frame_length,\n",
    "                                hop_length=self.frame_step)[0]\n",
    "        \n",
    "        # Estadísticas de energía\n",
    "        features.update({\n",
    "            'energy_mean': np.mean(rms),\n",
    "            'energy_std': np.std(rms),\n",
    "            'energy_range': np.ptp(rms),\n",
    "            'energy_skew': skew(rms),\n",
    "            'energy_kurtosis': kurtosis(rms)\n",
    "        })\n",
    "        \n",
    "        # Tasa de cruces por cero (relacionada con la frecuencia fundamental)\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio, \n",
    "                                               frame_length=self.frame_length,\n",
    "                                               hop_length=self.frame_step)[0]\n",
    "        features.update({\n",
    "            'zcr_mean': np.mean(zcr),\n",
    "            'zcr_std': np.std(zcr),\n",
    "            'zcr_skew': skew(zcr)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_spectral_features(self, audio):\n",
    "        \"\"\"Extrae características espectrales y cepstrales.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # MFCC con más coeficientes para capturar características del tracto vocal\n",
    "        mfccs = librosa.feature.mfcc(y=audio, \n",
    "                                   sr=self.sample_rate,\n",
    "                                   n_mfcc=self.n_mfcc,\n",
    "                                   n_fft=self.frame_length,\n",
    "                                   hop_length=self.frame_step,\n",
    "                                   window=self.window,\n",
    "                                   n_mels=self.nfilt)\n",
    "        \n",
    "        # Delta y Delta-Delta\n",
    "        mfccs_delta = librosa.feature.delta(mfccs)\n",
    "        mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "        \n",
    "        # Estadísticas para cada coeficiente MFCC y sus derivadas\n",
    "        for i in range(self.n_mfcc):\n",
    "            features.update({\n",
    "                f'mfcc_{i}_mean': np.mean(mfccs[i]),\n",
    "                f'mfcc_{i}_std': np.std(mfccs[i]),\n",
    "                f'mfcc_{i}_skew': skew(mfccs[i]),\n",
    "                f'mfcc_{i}_delta_mean': np.mean(mfccs_delta[i]),\n",
    "                f'mfcc_{i}_delta_std': np.std(mfccs_delta[i]),\n",
    "                f'mfcc_{i}_delta2_mean': np.mean(mfccs_delta2[i]),\n",
    "                f'mfcc_{i}_delta2_std': np.std(mfccs_delta2[i])\n",
    "            })\n",
    "        \n",
    "        # Formantes (resonancias del tracto vocal)\n",
    "        spec = np.abs(librosa.stft(audio, n_fft=self.frame_length, \n",
    "                                 hop_length=self.frame_step, \n",
    "                                 window=self.window))\n",
    "        \n",
    "        # Características espectrales adicionales\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(S=spec, \n",
    "                                                            sr=self.sample_rate)[0]\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(S=spec, \n",
    "                                                              sr=self.sample_rate)[0]\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(S=spec, \n",
    "                                                            sr=self.sample_rate)\n",
    "        \n",
    "        features.update({\n",
    "            'spectral_centroid_mean': np.mean(spectral_centroid),\n",
    "            'spectral_centroid_std': np.std(spectral_centroid),\n",
    "            'spectral_bandwidth_mean': np.mean(spectral_bandwidth),\n",
    "            'spectral_bandwidth_std': np.std(spectral_bandwidth),\n",
    "            'spectral_contrast_mean': np.mean(spectral_contrast),\n",
    "            'spectral_contrast_std': np.std(spectral_contrast)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_voice_quality_features(self, audio):\n",
    "        \"\"\"Extrae características de calidad de voz.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Jitter (variación de la frecuencia fundamental)\n",
    "        f0, voiced_flag, _ = librosa.pyin(audio, \n",
    "                                        fmin=librosa.note_to_hz('C2'),\n",
    "                                        fmax=librosa.note_to_hz('C7'),\n",
    "                                        sr=self.sample_rate)\n",
    "        \n",
    "        f0_voiced = f0[voiced_flag]\n",
    "        if len(f0_voiced) > 1:\n",
    "            # Jitter como la variación relativa promedio entre períodos consecutivos\n",
    "            jitter = np.mean(np.abs(np.diff(f0_voiced))) / np.mean(f0_voiced)\n",
    "            features['jitter'] = jitter\n",
    "        \n",
    "        # Shimmer (variación de la amplitud)\n",
    "        rms = librosa.feature.rms(y=audio,\n",
    "                                frame_length=self.frame_length,\n",
    "                                hop_length=self.frame_step)[0]\n",
    "        if len(rms) > 1:\n",
    "            # Shimmer como la variación relativa promedio de la amplitud\n",
    "            shimmer = np.mean(np.abs(np.diff(rms))) / np.mean(rms)\n",
    "            features['shimmer'] = shimmer\n",
    "        \n",
    "        # Harmonics-to-Noise Ratio (HNR)\n",
    "        # Aproximado usando la relación entre energía armónica y ruido\n",
    "        S = np.abs(librosa.stft(audio, n_fft=self.frame_length, \n",
    "                               hop_length=self.frame_step, \n",
    "                               window=self.window))\n",
    "        \n",
    "        # Calcular la energía armónica y el ruido\n",
    "        harmonic, percussive = librosa.decompose.hpss(S)\n",
    "        harmonic_energy = np.mean(harmonic**2)\n",
    "        noise_energy = np.mean(percussive**2)\n",
    "        \n",
    "        if noise_energy > 0:\n",
    "            hnr = 10 * np.log10(harmonic_energy / noise_energy)\n",
    "            features['hnr'] = hnr\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def process_audio(self, audio):\n",
    "        \"\"\"\n",
    "        Procesa un audio y extrae todas sus características.\n",
    "        \"\"\"\n",
    "        if len(audio) > self.sample_rate:\n",
    "            audio = audio[:self.sample_rate]\n",
    "        elif len(audio) < self.sample_rate:\n",
    "            audio = np.pad(audio, (0, self.sample_rate - len(audio)))\n",
    "        return self.extract_features(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speaker_feature_dataset(audio_files, preprocessor, feature_extractor):\n",
    "    all_features = []\n",
    "    for idx, file_info in enumerate(audio_files):\n",
    "        audio = preprocessor.process_audio(file_info['ruta_archivo'])\n",
    "        features = feature_extractor.process_audio(audio)\n",
    "        # Agregar etiquetas\n",
    "        features['palabra'] = file_info['palabra']\n",
    "        features['persona'] = file_info['persona']\n",
    "        \n",
    "        all_features.append(features)\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Procesados {idx + 1} archivos de {len(audio_files)}\")\n",
    "    \n",
    "    return pd.DataFrame(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear instancias\n",
    "preprocessor = preprocesing.AudioPreprocessor()\n",
    "feature_extractor = SpeakerFeatureExtractor()\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Obtener la primera fila del DataFrame\n",
    "first_row_df = df.head(1)\n",
    "\n",
    "features_df = create_speaker_feature_dataset(first_row_df.to_dict('records'), preprocessor, feature_extractor)\n",
    "\n",
    "features_df.to_csv('speaker_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
